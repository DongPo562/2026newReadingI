"""
test_api.py - NIM å¹³å° API è¿é€šæ€§æµ‹è¯•å·¥å…·
ç”¨æ³•ï¼špython test_api.py [model_id]
  model_id å¯é€‰ 1,3,5,6,7,8ï¼Œä¸ä¼ åˆ™æµ‹è¯•å…¨éƒ¨æ¨¡å‹
"""
import json
import sys
import os
import time
import argparse
import configparser
import urllib.request
import urllib.error
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ï¼ˆAPI å¯†é’¥ã€ä»£ç†ç­‰ï¼‰
load_dotenv()

# ============================================================
# æ¨¡å‹é…ç½®ï¼ˆä¸ ai_service.py ä¸­çš„ MODEL_REGISTRY ä¿æŒä¸€è‡´ï¼‰
# ============================================================
MODEL_REGISTRY = {
    1: {
        "name": "Kimi 2.5",
        "model": "moonshotai/kimi-k2.5",
        "temperature": 0.7,
        "top_p": 1.0,
        "max_tokens": 640,
        "max_tokens_business": 1024,
    },
    3: {
        "name": "DeepSeek V3.2",
        "model": "deepseek-ai/deepseek-v3.2",
        "temperature": 1,
        "top_p": 0.95,
        "max_tokens": 640,
        "max_tokens_business": 8192,
    },
    5: {
        "name": "MiniMax M2.1",
        "model": "minimaxai/minimax-m2.1",
        "temperature": 1,
        "top_p": 0.95,
        "max_tokens": 640,
        "max_tokens_business": 8192,
    },
    6: {
        "name": "GLM 4.7",
        "model": "z-ai/glm4.7",
        "temperature": 1,
        "top_p": 1,
        "max_tokens": 640,
        "max_tokens_business": 16384,
        "extra_body": {
            "chat_template_kwargs": {
                "enable_thinking": True,
                "clear_thinking": False,
            }
        },
    },
    7: {
        "name": "Doubao Seed 1.8",
        "model": "doubao-seed-1-8-251228",
        "temperature": 1,
        "top_p": 1,
        "max_tokens": 64,
        "max_tokens_business": 8192,
        "api_endpoint": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
        "api_key_env": "DOUBAO1.8_API_KEY",
        "use_proxy": False,
    },
    8: {
        "name": "DeepSeek Chat",
        "model": "deepseek-chat",
        "temperature": 1,
        "top_p": 0.95,
        "max_tokens": 64,
        "max_tokens_business": 8192,
        "api_endpoint": "https://api.deepseek.com/chat/completions",
        "api_key_env": "DEEPSEEK_API_KEY",
        "use_proxy": False,
    },
}

# API é…ç½®
API_ENDPOINT = "https://integrate.api.nvidia.com/v1/chat/completions"
DEFAULT_TEST_PROMPT = "ä½ å¥½,è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
DEFAULT_TIMEOUT = 20  # æµ‹è¯•ç”¨è¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œæ¯”æ­£å¸¸ä½¿ç”¨å®½æ¾ä¸€äº›


def get_nim_api_key():
    """è·å– API å¯†é’¥ï¼šä¼˜å…ˆç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡ config.ini"""
    key = os.environ.get("NIM_API_KEY", "").strip()
    if key:
        return key
    # å°è¯•ä» config.ini è¯»å–
    try:
        import configparser
        config = configparser.ConfigParser()
        config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "config.ini")
        config.read(config_path)
        key = config.get("QuizTrigger", "api_key", fallback="").strip()
        if key:
            return key
    except Exception:
        pass
    return ""


def _resolve_api_key_for_model(mc, nim_api_key):
    key_env = mc.get("api_key_env")
    if key_env:
        return (os.environ.get(key_env, "") or "").strip(), key_env
    return (nim_api_key or "").strip(), "NIM_API_KEY"


def get_reasoning_enabled():
    """è¯»å– config.ini çš„ reasoning å¼€å…³ï¼Œé»˜è®¤å…³é—­ã€‚"""
    try:
        config = configparser.ConfigParser()
        config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "config.ini")
        config.read(config_path)
        return config.getboolean("QuizTrigger", "enable_reasoning", fallback=False)
    except Exception:
        return False


def build_proxy_handler(use_proxy=True):
    """æ ¹æ®ç¯å¢ƒå˜é‡æ„é€ ä»£ç†å¤„ç†å™¨ï¼Œä¾¿äºç¡®è®¤æœ¬åœ°ä»£ç†ç”Ÿæ•ˆã€‚"""
    if not use_proxy:
        return urllib.request.ProxyHandler({})
    http_proxy = os.environ.get("HTTP_PROXY", "").strip()
    https_proxy = os.environ.get("HTTPS_PROXY", "").strip()
    proxies = {}
    if http_proxy:
        proxies["http"] = http_proxy
    if https_proxy:
        proxies["https"] = https_proxy
    return urllib.request.ProxyHandler(proxies)


def _extract_text_content(content):
    if isinstance(content, str):
        return content.strip()
    if isinstance(content, list):
        chunks = []
        for item in content:
            if isinstance(item, str):
                chunks.append(item)
                continue
            if not isinstance(item, dict):
                continue
            item_type = str(item.get("type", "")).lower()
            if item_type in ("text", "output_text"):
                text = item.get("text")
                if isinstance(text, str):
                    chunks.append(text)
        merged = "".join(chunks).strip()
        return merged if merged else None
    return None


def _looks_like_reasoning_param_error(error_text):
    lowered = str(error_text).lower()
    markers = ("chat_template_kwargs", "thinking", "unexpected", "invalid", "unknown")
    return any(x in lowered for x in markers)


def build_business_prompt(content, sentence_content):
    return (
        "ç”¨æˆ·ä¸ºè‹±è¯­å­¦ä¹ è€…ï¼Œæ¯è¯­æ˜¯ä¸­æ–‡ï¼Œè¯·æ‰®æ¼”è€ƒå®˜ï¼Œæ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€é“è‹±è¯­è€ƒé¢˜ã€‚"
        f"å†…å®¹ï¼š{content}ï¼Œæ‰€åœ¨å¥å­ï¼š{sentence_content}ã€‚"
        "è¯·éšæœºé€‰æ‹©å‡ºä¸€é“é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜æˆ–é—®ç­”é¢˜ã€‚"
        "è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š"
        "typeï¼ˆchoice æˆ– fill æˆ– qaï¼‰ã€questionï¼ˆé¢˜ç›®æ–‡æœ¬ï¼‰ã€"
        "optionsï¼ˆé€‰æ‹©é¢˜æ—¶ä¸ºå››ä¸ªé€‰é¡¹çš„æ•°ç»„ï¼Œå…¶ä»–é¢˜å‹çœç•¥æ­¤å­—æ®µï¼‰ã€answerï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰ã€‚"
        "åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"
    )


def test_model(model_id, nim_api_key, enable_reasoning, test_prompt, timeout, business_mode):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„ API è¿é€šæ€§"""
    mc = MODEL_REGISTRY[model_id]
    endpoint = mc.get("api_endpoint", API_ENDPOINT)
    api_key, key_source = _resolve_api_key_for_model(mc, nim_api_key)
    use_proxy = mc.get("use_proxy", True)
    print(f"\n{'='*60}")
    print(f"  æµ‹è¯•æ¨¡å‹ #{model_id}: {mc['name']}")
    print(f"  model: {mc['model']}")
    print(f"  endpoint: {endpoint}")
    print(f"  key_env: {key_source}")
    print(f"  proxy: {'ON (use system proxy)' if use_proxy else 'OFF (direct connection)'}")
    print(f"{'='*60}")

    if not api_key:
        print("  [ç»“æœ] âŒ æœªæ‰¾åˆ° API å¯†é’¥")
        print(f"  [è¯¦æƒ…] è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® {key_source}")
        return False

    base_payload = {
        "model": mc["model"],
        "messages": [{"role": "user", "content": test_prompt}],
        "temperature": mc["temperature"],
        "top_p": mc["top_p"],
        "max_tokens": mc["max_tokens_business"] if business_mode else mc["max_tokens"],
        "stream": False,
    }
    if "extra_body" in mc:
        base_payload.update(mc["extra_body"])
    opener = urllib.request.build_opener(build_proxy_handler(use_proxy))

    print(f"  [è¯·æ±‚] POST {endpoint}")
    print(f"  [è¯·æ±‚] timeout={timeout}s")
    print(f"  [è¯·æ±‚] max_tokens={base_payload['max_tokens']}")
    start_time = time.time()

    try:
        payload_candidates = []
        payload_with_reasoning = dict(base_payload)
        reasoning_added = False
        chat_template_kwargs = payload_with_reasoning.get("chat_template_kwargs")
        if isinstance(chat_template_kwargs, dict):
            # æ¨¡å‹è‡ªå¸¦ chat_template_kwargs æ—¶ï¼Œä»…åœ¨å·²æœ‰ thinking å­—æ®µæ—¶è¦†ç›–
            if "thinking" in chat_template_kwargs:
                payload_with_reasoning["chat_template_kwargs"] = dict(chat_template_kwargs)
                payload_with_reasoning["chat_template_kwargs"]["thinking"] = enable_reasoning
                reasoning_added = True
        else:
            payload_with_reasoning["chat_template_kwargs"] = {"thinking": enable_reasoning}
            reasoning_added = True
        if reasoning_added:
            payload_candidates.append((payload_with_reasoning, True))
        payload_candidates.append((base_payload, False))

        obj = None
        status = None
        text = ""
        for payload, has_reasoning_param in payload_candidates:
            body = json.dumps(payload).encode("utf-8")
            request = urllib.request.Request(
                endpoint,
                data=body,
                method="POST",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {api_key}",
                },
            )
            try:
                with opener.open(request, timeout=timeout) as response:
                    status = response.status
                    text = response.read().decode("utf-8")
                    obj = json.loads(text)
                    break
            except urllib.error.HTTPError as e:
                detail = e.read().decode("utf-8", errors="ignore")
                if has_reasoning_param and _looks_like_reasoning_param_error(detail):
                    print("  [æç¤º] å½“å‰æ¨¡å‹ä¸æ¥å— thinking å‚æ•°ï¼Œè‡ªåŠ¨å›é€€é»˜è®¤è¯·æ±‚")
                    continue
                raise

        if obj is None:
            raise RuntimeError("empty response object after all payload attempts")

        elapsed = time.time() - start_time

        # æå–å›å¤å†…å®¹ï¼ˆå…¼å®¹ä¸åŒæ¨¡å‹çš„è¿”å›æ ¼å¼ï¼‰
        content = None
        reasoning = None
        if isinstance(obj, dict):
            choices = obj.get("choices")
            if isinstance(choices, list) and choices:
                msg = choices[0].get("message") or {}
                content = _extract_text_content(msg.get("content"))
                reasoning = msg.get("reasoning_content")
            # å…œåº•ï¼šé¡¶å±‚ content
            if not content:
                content = _extract_text_content(obj.get("content"))

        # æå– usage ä¿¡æ¯
        usage = obj.get("usage") or {}

        print(f"  [ç»“æœ] âœ… æˆåŠŸï¼HTTP {status}ï¼Œè€—æ—¶ {elapsed:.2f}s")
        if content:
            print(f"  [å›å¤] {str(content)[:200]}")
        elif enable_reasoning and reasoning:
            print(f"  [å›å¤(reasoning)] {str(reasoning)[:200]}")
        else:
            print(f"  [å›å¤] (content ä¸ºç©º)")
        if usage:
            print(f"  [ç”¨é‡] prompt_tokens={usage.get('prompt_tokens', '?')}, "
                  f"completion_tokens={usage.get('completion_tokens', '?')}, "
                  f"total_tokens={usage.get('total_tokens', '?')}")
        # å¦‚æœ content å’Œ reasoning éƒ½ä¸ºç©ºï¼Œæ‰“å°åŸå§‹å“åº”å¸®åŠ©è°ƒè¯•
        if not content and not reasoning:
            print(f"  [åŸå§‹å“åº”] {text[:500]}")
        return True

    except urllib.error.HTTPError as e:
        elapsed = time.time() - start_time
        detail = e.read().decode("utf-8", errors="ignore")
        print(f"  [ç»“æœ] âŒ HTTP é”™è¯¯ï¼çŠ¶æ€ç  {e.code}ï¼Œè€—æ—¶ {elapsed:.2f}s")
        print(f"  [è¯¦æƒ…] {detail[:300]}")
        return False

    except urllib.error.URLError as e:
        elapsed = time.time() - start_time
        print(f"  [ç»“æœ] âŒ ç½‘ç»œé”™è¯¯ï¼è€—æ—¶ {elapsed:.2f}s")
        print(f"  [è¯¦æƒ…] {e.reason}")
        return False

    except Exception as e:
        elapsed = time.time() - start_time
        print(f"  [ç»“æœ] âŒ å¼‚å¸¸ï¼è€—æ—¶ {elapsed:.2f}s")
        print(f"  [è¯¦æƒ…] {type(e).__name__}: {e}")
        return False


def main():
    print("\n" + "#" * 60)
    print("#  NIM å¹³å° API è¿é€šæ€§æµ‹è¯•")
    print("#" * 60)

    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument("model_id", nargs="?", type=int, help="å¯é€‰ï¼Œ1,3,5,6,7")
    parser.add_argument("--business", action="store_true", help="ä½¿ç”¨ä¸ä¸šåŠ¡ä¸€è‡´çš„å‡ºé¢˜æç¤ºè¯å’Œ max_tokens")
    parser.add_argument("--content", default="keeps adding", help="ä¸šåŠ¡æ¨¡å¼ä¸‹çš„ content")
    parser.add_argument("--sentence", default="7. It keeps adding onto itself.", help="ä¸šåŠ¡æ¨¡å¼ä¸‹çš„ sentence_content")
    parser.add_argument("--timeout", type=float, default=DEFAULT_TIMEOUT, help="è¯·æ±‚è¶…æ—¶ç§’æ•°")
    parser.add_argument("--prompt", default=DEFAULT_TEST_PROMPT, help="è‡ªå®šä¹‰æ™®é€šæµ‹è¯•æç¤ºè¯")
    args = parser.parse_args()

    test_prompt = build_business_prompt(args.content, args.sentence) if args.business else args.prompt

    # è·å–é»˜è®¤ NIM API å¯†é’¥ï¼ˆéƒ¨åˆ†æ¨¡å‹ä¼šä½¿ç”¨ç‹¬ç«‹ key_envï¼‰
    nim_api_key = get_nim_api_key()

    # æ˜¾ç¤ºä»£ç†é…ç½®
    http_proxy = os.environ.get("HTTP_PROXY", "")
    https_proxy = os.environ.get("HTTPS_PROXY", "")

    safe_api_key = (
        f"{nim_api_key[:12]}...{nim_api_key[-4:]}"
        if len(nim_api_key) >= 16 else "(æœªè®¾ç½®æˆ–é•¿åº¦å¼‚å¸¸)"
    )
    enable_reasoning = get_reasoning_enabled()
    print(f"\n  NIM API Key: {safe_api_key}")
    print(f"  Default Endpoint: {API_ENDPOINT}")
    print(f"  Timeout: {args.timeout}s")
    print(f"  HTTP_PROXY: {http_proxy or '(æœªè®¾ç½®)'}")
    print(f"  HTTPS_PROXY: {https_proxy or '(æœªè®¾ç½®)'}")
    print(f"  Reasoning: {'ON' if enable_reasoning else 'OFF'}")
    print(f"  Business Mode: {'ON' if args.business else 'OFF'}")
    print(f"  Test Prompt: \"{test_prompt}\"")

    # ç¡®å®šè¦æµ‹è¯•çš„æ¨¡å‹
    if args.model_id is not None:
        target_id = args.model_id
        if target_id not in MODEL_REGISTRY:
            print(f"\n  âŒ æ— æ•ˆçš„ model_id: {target_id}ï¼ˆå¯é€‰ 1,3,5,6,7,8ï¼‰")
            sys.exit(1)
        test_ids = [target_id]
    else:
        test_ids = sorted(MODEL_REGISTRY.keys())

    # é€ä¸ªæµ‹è¯•
    results = {}
    for mid in test_ids:
        results[mid] = test_model(
            mid,
            nim_api_key,
            enable_reasoning,
            test_prompt,
            args.timeout,
            args.business
        )

    # æ±‡æ€»ç»“æœ
    print(f"\n\n{'='*60}")
    print("  æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    for mid in test_ids:
        mc = MODEL_REGISTRY[mid]
        status = "âœ… é€šè¿‡" if results[mid] else "âŒ å¤±è´¥"
        print(f"  #{mid} {mc['name']:20s} {status}")
    print()

    # æ¨è
    passed = [mid for mid in test_ids if results[mid]]
    if passed:
        print(f"  ğŸ’¡ å»ºè®®åœ¨ config.ini ä¸­è®¾ç½® model_id = {passed[0]}")
    else:
        print("  âš ï¸  æ‰€æœ‰æ¨¡å‹å‡æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API å¯†é’¥")


if __name__ == "__main__":
    main()
